---
title: "Data set building"
author: "Alain Lesaffre"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---
```{r  init, echo=FALSE, message=FALSE, warning=FALSE}
options( scipen = 99999)
library(tidyverse)
library(dplyr)
library(vtreat)
library(DataExplorer)
library(ggplot2)
library(ggshadow)
library(readr)
library(readxl)
library(performance)
library(caret)
library(ranger)
source("./common.R")
c4c_data   <-janitor::clean_names(readxl::read_xlsx(c4c_file ))
bci_data   <-janitor::clean_names(readxl::read_xlsx(dulux_raw_file, sheet="BCI Lead data" ) )
opportunity_data <-janitor::clean_names( read.csv(opportunity_file )) %>%
                            dplyr::mutate( date = stringr::str_sub( created_on, 1L, 19L),
                                           date = stringr::str_replace( date ,"T", " "),
                                           date =as.POSIXct(date)) %>% 
                            dplyr::mutate( opportunity = 1) %>% 
                            dplyr::select( btd_reference_id, date, opportunity)


op_c4c_data  <- c4c_data   %>% 
                        dplyr::inner_join( opportunity_data, by=c( "id" = "btd_reference_id")) 
starting_date  <-min(op_c4c_data$date)

noop_c4c_data  <-c4c_data  %>%
                       dplyr::mutate( date = stringr::str_sub( creation_date_time, 1L, 19L),
                                      date = as.POSIXct(date) )%>%
                       dplyr::filter( !(id %in% op_c4c_data$id)) %>%
                       dplyr::mutate( opportunity = 0)


to_remove_from_op_c4c <-names(op_c4c_data)[!(names(op_c4c_data) %in% names(noop_c4c_data))]
op_c4c_data           <- op_c4c_data %>%
                                 select(-to_remove_from_op_c4c)
clean_c4c_data <- dplyr::bind_rows( noop_c4c_data,
                                 op_c4c_data  )


all_data   <-bci_data  %>%
                      dplyr::inner_join(clean_c4c_data, by=c( "projectid" = "external_id")) %>% 
                      dplyr::select("projectid","name", "company", "qualification_level_code_text", "user_status_code_text" ,"account_life_cycle_status_code_text",
                                    "priority_code_text",  "group_code_text", "account_state", "consistency_status_code_text",
                                    "project_type", "projectstage","project_status" ,"remarks", "origin_type_code_text", "creation_date_time",
                                    "life_cycle_status_code_text", "value", "contact_uuid","opportunity") %>%
                      dplyr::mutate( creation_date_time = stringr::str_sub(creation_date_time, 1,19),
                                     creation_date = as.POSIXct(creation_date_time),
                                     beg_date      = as.Date(creation_date)) %>%
                      dplyr::mutate( log_value = log(value)) %>%
                      dplyr::select(-creation_date_time, - contact_uuid ) 



lubridate::day(all_data$beg_date) <-1

#
#
#  As in EDA
#
#
all_data <-all_data %>% 
             dplyr::mutate( project_type = stringr::str_to_lower(project_type),
                            type = ifelse( stringr::str_detect(project_type, "apartment"),
                                           "apartment", 
                                           NA),
                            type = ifelse( is.na(type) & stringr::str_detect(project_type, "townhouse"),
                                           "townhouse", 
                                           type),
                            type = ifelse( is.na(type) & stringr::str_detect(project_type, "house|chalet"),
                                           "house", 
                                           type),
                            type = ifelse( is.na(type) & stringr::str_detect(project_type, "commercial|motel|hotel|showroom|industrial|supermarket|factory"),
                                           "commercial", 
                                           type),
                             type = ifelse( is.na(type) & stringr::str_detect(project_type, "office"),
                                           "commercial", 
                                           type),
                             type = ifelse( is.na(type) & stringr::str_detect(project_type, "road"),
                                           "road", 
                                           type),
                            type = ifelse( is.na(type) & stringr::str_detect(project_type, "streetscap|intersection"),
                                           "road", 
                                           type),
                            type = ifelse( is.na(type) & stringr::str_detect(project_type, "aged care|retirement"),
                                           "aged_care", 
                                           type),
                            type = ifelse( is.na(type) & stringr::str_detect(project_type, "retirement village|senior living villa|senior living unit"),
                                           "aged_care", 
                                           type),
                            type = ifelse( is.na(type) & stringr::str_detect(project_type, "cycle"),
                                           "road", 
                                           type),
                            type = ifelse( is.na(type) & stringr::str_detect(project_type, "hotel"),
                                           "hospitality", 
                                           type),
                             type = ifelse( is.na(type) & stringr::str_detect(project_type, "restaurant"),
                                           "hospitality", 
                                           type),
                            type = ifelse( is.na(type) & stringr::str_detect(project_type, "prison|school|classroom|community centre|social housing|bridge|childcare centre|hospital|medical|water infrastructure|childcare centre|airport"),
                                           "public", 
                                           type),
                            type  = ifelse( is.na(type), 
                                            "other",
                                            type)
                            )
all_data <-all_data %>% 
             dplyr::mutate( project_status =ifelse( stringr::str_detect(project_status, "Rezoning|Tenders To Be Called|Site Works Commenced|Construction Certificate Approved|Development Approval|Tenders Called"), "big_effect",project_status ))
saveRDS(all_data, second_data)
```
# Summary

In this document, we build a new data set compare to the one used in **EDA**. The point is to add mre fields, the response we are working with is the opportunities, which is this case is very different that in **EDA** for Warm but similar for Hot. 

To reach good prediction we transform the data using conditional probability based on the effect. 

# Overview

The data set has been built based on the date of the first oppurtunity, all observation before this sdate has been removed. One could notice that the field user_status_code_text with **Converted** the meaning is not a transformation in opportunity. 

The data set information are the following:

|  Attribute           | Value     |
|----------------------|-----------|
| Starting Date        | `r as.character(starting_date)` |
| Number observations  | `r nrow(all_data)` | 
| Number of hot        | `r sum( all_data$qualification_level_code_text =="Hot")`|
| Number of warm        | `r sum( all_data$qualification_level_code_text =="Warm")`|
| Median value hot     | `r median( all_data$value[all_data$qualification_level_code_text =="Hot"])`|
| Opportunities        | `r sum(all_data$opportunity)` |
| Hot Opportunities    | `r sum(all_data$opportunity[all_data$qualification_level_code_text =="Hot"], na.rm = TRUE)`|
| Warm Opportunities   | `r sum(all_data$opportunity[all_data$qualification_level_code_text =="Warm"], na.rm = TRUE)` |
| Number converted     | `r sum(all_data$user_status_code_text =="Converted")` |
| Number Hot converted | `r sum(all_data$user_status_code_text[all_data$qualification_level_code_text =="Hot"] =="Converted")`|
| Number Warm converted | `r sum(all_data$user_status_code_text[all_data$qualification_level_code_text =="Warm"] =="Converted")`|
| Percent Hot converted  | `r round(sum(all_data$user_status_code_text[all_data$qualification_level_code_text =="Hot"] =="Converted")/ sum(all_data$qualification_level_code_text =="Hot", na.rm = TRUE),4)* 100`|
| Percent Warm converted | `r round(sum(all_data$user_status_code_text[all_data$qualification_level_code_text =="Warm"] =="Converted")/ sum(all_data$qualification_level_code_text =="Warm", na.rm = TRUE),4)* 100`|
| Percent Hot opportunity  | `r round(sum(all_data$opportunity[all_data$qualification_level_code_text =="Hot"])/ sum(all_data$qualification_level_code_text =="Hot", na.rm = TRUE),4)* 100`|
| Percent Warm opportunity  | `r round(sum(all_data$opportunity[all_data$qualification_level_code_text =="Warm"])/ sum(all_data$qualification_level_code_text =="Warm", na.rm = TRUE),4)* 100`|


The project type after transformation are distributed as follow, the other could be further transformed:

```{r type_porject,echo=FALSE}
knitr::kable(table(all_data$type), col.names = c("Type","Number occurences"))
```


The value of the opportunities based on the qualification Hot or Warm is as follow.

```{r value_op, echo=FALSE, fig.align="center"}
ggplot( data = all_data, aes(x=log_value))+
        geom_density(aes(group=qualification_level_code_text, fill=qualification_level_code_text, col=qualification_level_code_text), alpha=.8) +
        # geom_rug()+
        theme_minimal()+
        labs(title="Values / Oppotunity",
             x="log value",
             y="Frequency")

```

## Data preparation 
```{r vtreat, warning =FALSE,echo=FALSE}
variables_to_process <-c("type","log_value", "account_state", "project_status", "projectstage", "consistency_status_code_text", "life_cycle_status_code_text")


warm_data   <- all_data %>%
                   dplyr::filter( qualification_level_code_text =="Warm")
plan_data <-vtreat::designTreatmentsC(
        warm_data,
        varlist = variables_to_process,
        outcomename = "opportunity",
        outcometarget =  1,
        verbose  = FALSE
)
warm_to_process <-vtreat::prepare(plan_data ,
                                  warm_data)
```

Due to the fact that we deal with quantitative variables, we do further transformation such as mapping the effect of the categories. This transformation adds a level of complexity concerning the interpretation as we deal with conditional probability. As we shall see below the results one **Warm** are acceptable. 

# Time factor 
```{r time, echo=FALSE}
cycle_vic <- all_data  %>%
                   dplyr::filter( account_state =="VIC") %>%
                   dplyr::group_by(beg_date) %>%
                   dplyr::summarise(nb_opportunity = sum( opportunity ==1),
                                    lost_opportunity = sum( opportunity == 0))
                   

```

Construction is cyclic, in the following garphic we show the opportunity for Victoria.

```{r vic_dsp, echo=FALSE,fig.align="center"}
ggplot( data = cycle_vic)+
  geom_line( aes( x= beg_date, y= nb_opportunity, group=1), col="orange", size=1) +
  theme_minimal()

```





# Simple models 
```{r simple_models, echo=FALSE, warning= FALSE}
warm_model <-glm( opportunity  ~ .,
                  family = binomial,
                  data = warm_to_process %>% select( !which(stringr::str_detect(names(warm_to_process), "catP$"))))
warm_predict <-predict(warm_model  , type = "response")
logistics_deviance <-sum(-2*log(abs(warm_to_process$opportunity -warm_predict)))
deviance_warm <- residuals(warm_model , type = "response")
to_check <-as.data.frame.matrix( summary(warm_model)$coefficients)
```

As we shall see with **Hot** as well, we have do not have significant coefficient in linear model but good prediction, which  are confirmed using a tree ensemble. What does this mean really? 


The results for **Warm** are as follow with cut off of .5 and the **catB** only, the transformation in this case is totally based on effect:

| Reference       | Value  |
|-----------------|--------|
|  True positive  | `r sum( warm_to_process$opportunity ==1 & warm_predict > .5)` |
|  False positive | `r sum( warm_to_process$opportunity ==0 & warm_predict > .5)` |
|  False negative | `r sum( warm_to_process$opportunity ==1 & warm_predict <= .5)` |
|  True negative  | `r sum( warm_to_process$opportunity ==0  & warm_predict <= .5)` |

The *working* residual is very small with such a prediction, the total residual is of `r sum(deviance_warm)`.


Some variables used are the conditional probabilities expresses as *opportunity | category variables*. 

We should not forget that we have  converted the **type**, **state** and **project state** with conditional probability. Using type of project, which is a transformed data, the **other** category has a probability of .33 to be a non opportunity, or **road** with have 0.065 to be a non opportunity as shown below the apartment has a value of .15 as in hot this value of .55.  


Most significant variables:

1. log of the value 
2. The type transformed  (Conditional probability) 
3. The hot encoding of the type (Transform data as shown above)
4. The life_cycle_status_code (Conditional probability)
5. The hot encoding life_cycle_status_code (Not transformed) 


## Hot Model
```{r hotmooel, echo=FALSE, warning=FALSE}
variables_to_process <-c("type","log_value", "account_state", "project_status", "projectstage", "consistency_status_code_text", "life_cycle_status_code_text")


hot_data   <- all_data %>%
                   dplyr::filter( qualification_level_code_text =="Hot")
plan_data <-vtreat::designTreatmentsC(
        hot_data,
        varlist = variables_to_process,
        outcomename = "opportunity",
        outcometarget =  1,
        verbose  = FALSE
)
hot_to_process <-vtreat::prepare(plan_data ,
                                  hot_data)

hot_model <-glm( opportunity  ~ .,
                  family = binomial,
                  data = hot_to_process %>% select( !which(stringr::str_detect(names(hot_to_process), "catP$"))))

hot_predict <-predict(hot_model  , type = "response")
deviance_hot <- residuals(hot_model , type = "response")
```

We build a global **Hot** model similar to to **Warm**, the only difference is the size of the data set, which is of `r nrow(hot_data)` observations. 


The results for **Hot** are as follow with cut off of .5 and the **catB** only, the transformation in this case is totally based on effect:

| Reference       | Value  |
|-----------------|--------|
|  True positive  | `r sum( hot_to_process$opportunity ==1 & hot_predict > .5)` |
|  False positive | `r sum( hot_to_process$opportunity ==0 & hot_predict > .5)` |
|  False negative | `r sum( hot_to_process$opportunity ==1 & hot_predict <= .5)` |
|  True negative  | `r sum( hot_to_process$opportunity ==0  & hot_predict <= .5)` |

The *working* residual is very small with such a prediction, the total residual is of `r sum(deviance_hot)`. And the most significant value is the log of the value based on the Z value.  

Most significant variable:

1. log of the value 
2. The life_cycle_status_code (Conditional probability)
3. The life_cycle_status_code  hot encoding Converted and Qualified 

The R2 is of `r r2(hot_model)`, which is *good*.

A more detail view of the model with parameters, it is not optimum as the sd includes zero most of the time. The main question is how the model will behave based on new information. As the sd is high, too high.  


```{r dsp_coef_model, echo=FALSE}
modelsummary::modelsummary(hot_model)
```

We can ask ourselef here, if we use an ensemble the sd would be better lower, what is surprising is the low value of working residual. 

hot_to_prhot## Build tree 
```{r ranger_tree, echo=FALSE}
library(ranger)
ranger_model_hot <-ranger(  opportunity  ~ .,
                            data = hot_to_process %>% select( !which(stringr::str_detect(names(hot_to_process), "catP$"))))
hot_ranger_predict <-predict(ranger_model_hot, data= hot_to_process %>% select( !which(stringr::str_detect(names(hot_to_process), "catP$"))))
```

As mentioned we now build a tree to avoid the instability. The results are show below, there is nearly no diffrence between the linear model and the tree type of model, apart from a small change in false positive. For simplicity we could stay with the linear model. The next step will be to use cross valiadtion to check the stability of the model.  

\

| Reference       | Value  |
|-----------------|--------|
|  True positive  | `r sum( hot_to_process$opportunity ==1 & hot_ranger_predict$predictions > .5)` |
|  False positive | `r sum( hot_to_process$opportunity ==0 & hot_ranger_predict$predictions > .5)` |
|  False negative | `r sum( hot_to_process$opportunity ==1 & hot_ranger_predict$predictions <= .5)` |
|  True negative  | `r sum( hot_to_process$opportunity ==0  & hot_ranger_predict$predictions <= .5)` |


Out of the false positives, it could be of interest to check what are those observations? Are they exceptional? 

```{r cross_validation, echo=FALSE, message=FALSE}
hot_control <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)

rf_caret_hot <- train(as.factor(opportunity) ~ ., 
                data =hot_to_process %>% select( !which(stringr::str_detect(names(hot_to_process), "catP$"))), 
                method = "ranger",
                trControl = hot_control)

rf_cater_res <-predict(rf_caret_hot, data = hot_to_process %>% select( !which(stringr::str_detect(names(hot_to_process), "catP$"))))
confusionMatrix(rf_cater_res, as.factor(hot_to_process$opportunity))
```



## Some details about the preprocessing

The preprocessing is made by modeling the inferences. The **CatB** is the contribution to non informative level, this is an impact variable therefor for type the impact is:
$$ Impact(type) = E[type|Category] - E[type]$$







